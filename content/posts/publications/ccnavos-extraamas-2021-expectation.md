---
title: >
  Expectation: Personalized Explainable Artificial Intelligence for Decentralized Agents with Heterogeneous Knowledge
date: 2021-07-04T00:00:00+01:00
authors:
  - dc
  - gc
  - an
  - ra
  - lvdt
  - ao
  - ms
tags:
  - HES-SO
  - UNIBO
  - UNILU
  - OZU
  - Extraamas
  - "2021"
weight: 1000
---

by {{<dc>}}, {{<gc>}}, {{<an>}}, {{<ra>}}, {{<lvdt>}}, {{<ao>}}, and {{<ms>}}

## Abstract 

{{<justified>}}


Explainable AI (XAI) has emerged in recent years as a set of techniques and methodologies to interpret and explain machine learning (ML) predictors. 
To date, many initiatives have been proposed. 
Nevertheless, current research efforts mainly focus on methods tailored to specific ML tasks and algorithms, such as image classification and sentiment analysis. 
However, explanation techniques are still embryotic, and they target principally ML experts rather than heterogeneous end-users. 
Furthermore, existing solutions assume data to be centralized, homogeneous, and fully/continuously accessible, a situation which rarely holds in practice. 
Arguably, a system-wide perspective is currently missing. 
The project named “Personalized Explainable Artificial Intelligence for Decentralized Agents with Heterogeneous Knowledge” (Expectation) aims at overcoming such limitations. 
This manuscript presents the overall objectives and approach of the Expectation project, focusing on advancing both theoretically and practically the state of the art of XAI towards the construction of personalized explanations in spite of decentralization and heterogeneity of knowledge, agents, and explainee (both humans or virtual). 
To tackle the challenges posed by personalization, decentralization, and heterogeneity, the project fruitfully combines abstractions, methods, and approaches from the multi-agent systems, knowledge extraction and injection, negotiation, argumentation, and symbolic reasoning communities.

{{</justified>}}

## How to cite

### Bibtex

```bibtex
@InProceedings{ccnavos-extraamas-2021-expectation,
  TBD
}
```